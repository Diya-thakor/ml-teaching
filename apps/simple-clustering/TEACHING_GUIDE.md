# Teaching Guide: Simple Image Clustering

## ğŸ¯ Learning Objectives

By the end of this demo, students should understand:

1. **Feature representation** - How we describe pixels/patches
2. **Clustering basics** - K-Means algorithm
3. **Feature engineering** - Hand-crafted vs learned features
4. **Trade-offs** - Speed vs accuracy, simplicity vs power
5. **Transfer learning** - Using pretrained models (ResNet18)

## ğŸ“– Recommended Teaching Flow

### Part 1: Introduction (5 minutes)

**Setup**:
- Open the app
- Select a colorful image (e.g., "tulip_field.jpg")
- Show the original image

**Questions to ask**:
- "How would you describe this pixel to a computer?"
- "What makes two pixels similar?"
- "How can we group similar pixels together?"

**Introduce**: K-Means clustering concept

---

### Part 2: RGB Clustering (10 minutes)

**Navigate to**: Tab 1 (RGB Colors)

**Demo**:
1. Set K=4 clusters
2. Run clustering on tulip field
3. Point out: Each color (red, yellow, green, blue) forms a cluster

**Explain**:
- Feature: `[R, G, B]` values (3 numbers per pixel)
- K-Means groups pixels with similar RGB values
- Fast and intuitive!

**Show limitation**:
1. Switch to "sunset_beach.jpg"
2. Point out: Sky and ocean both blue â†’ same cluster!
3. Ask: "Is this what we want? Sky and ocean are different things!"

**Key insight**: Color alone isn't enough

---

### Part 3: Position Clustering (10 minutes)

**Navigate to**: Tab 2 (Position X,Y)

**Demo**:
1. Use same beach image
2. Set K=4 clusters
3. Show how image gets divided spatially

**Explain**:
- Feature: `[X/width, Y/height]` (2 numbers per pixel)
- Creates spatial regions (top, bottom, left, right)
- Spatially coherent!

**Show limitation**:
- Point out: Sky and ocean NOW separate (good!)
- But: Clouds and sand might be in same cluster if both on left side (bad!)

**Key insight**: Position alone also isn't enough

---

### Part 4: Combined Approach (15 minutes)

**Navigate to**: Tab 3 (RGB + Position)

**Demo 1**: Balanced weights
1. RGB weight = 1.0, Position weight = 0.5
2. Run on beach image
3. Show: Sky and ocean NOW separate! âœ¨

**Explain**:
- Feature: `[R, G, B, X, Y]` (5 numbers)
- Combines color AND position
- Best of both worlds!

**Interactive experiment**:
1. **Experiment A**: Set RGB weight = 2.0, Position weight = 0.1
   - Ask: "What do you expect?"
   - Show: Acts like Tab 1 (color-dominant)

2. **Experiment B**: Set RGB weight = 0.1, Position weight = 2.0
   - Ask: "What do you expect?"
   - Show: Acts like Tab 2 (position-dominant)

3. **Experiment C**: Find best balance
   - Let students suggest weights
   - Try different values interactively

**Key insight**: Feature engineering = choosing AND weighting features

---

### Part 5: Deep Learning (20 minutes)

**Navigate to**: Tab 4 (ResNet18 Features)

**Setup**:
1. Explain: "So far we used hand-crafted features (RGB, XY)"
2. Ask: "Can a neural network learn better features automatically?"
3. Introduce: ResNet18 (pretrained CNN)

**Demo 1**: Whole image approach
1. Select "Whole image (single vector)"
2. Show the 512-dimensional feature vector
3. Explain why this doesn't work for pixel clustering

**Key point**: One vector describes whole image, can't cluster pixels!

**Demo 2**: Patch-based approach
1. Select "Patch-based"
2. Set patch size = 56, stride = 28
3. Watch it extract patches and cluster

**Explain**:
- Divide image into overlapping patches
- Each patch â†’ ResNet18 â†’ 512 numbers
- Cluster the 512-dim vectors

**Compare results**:
1. Go back to Tab 3 (RGB+Position)
2. Come back to Tab 4 (ResNet18)
3. Ask: "What's different?"

**Point out**:
- ResNet18 understands **semantics** (meaning)
- "This looks like sky" vs "This looks like water"
- Works even when colors are similar!

**Show power**:
1. Use "autumn_forest.jpg"
2. Tab 3: Struggles (many colors, complex)
3. Tab 4: Better (groups trees, sky, ground semantically)

---

### Part 6: Comparison & Discussion (10 minutes)

**Create comparison table on board**:

| Method | Speed | Features | Best For |
|--------|-------|----------|----------|
| RGB | âš¡âš¡âš¡ | 3D | Distinct colors |
| Position | âš¡âš¡âš¡ | 2D | Spatial regions |
| RGB+Position | âš¡âš¡âš¡ | 5D | Balanced segmentation |
| ResNet18 | ğŸ¢ | 512D | Semantic understanding |

**Discussion questions**:
1. "When would you use RGB clustering?"
   - Answer: Simple color segmentation, fast processing

2. "When would you use position clustering?"
   - Answer: Analyzing image regions, grid-based tasks

3. "When would you use ResNet18?"
   - Answer: Need semantic understanding, accuracy > speed

4. "What's the trade-off?"
   - Answer: Simplicity vs power, speed vs accuracy

---

### Part 7: Advanced Topics (Optional, 10 minutes)

**Topic 1**: Why ResNet18 instead of DINOv3?
- ResNet18: 512-dim, supervised, simpler, faster
- DINOv3: 768-dim, self-supervised, SOTA, slower
- ResNet18 great for learning, DINOv3 for research

**Topic 2**: Feature dimensions
- More dimensions â‰  always better
- Need enough samples (curse of dimensionality)
- ResNet18's 512-dim is sweet spot

**Topic 3**: Transfer learning
- ResNet18 trained on ImageNet (1000 classes)
- We use it for clustering (different task!)
- Features learned for classification â†’ useful for clustering too!

---

## ğŸ§ª Suggested Exercises

### Exercise 1: Color Dominance Test
**Image**: Tulip field
**Task**: Which method works best?
**Expected**: RGB clustering (colors are very distinct)

### Exercise 2: Sky-Ocean Problem
**Image**: Sunset beach
**Task**: Use RGB only â†’ see problem. Use RGB+Position â†’ see solution.
**Expected**: Students understand why combined features help

### Exercise 3: Weight Tuning
**Image**: City skyline
**Task**: Find best RGB and Position weights
**Expected**: Students experiment and understand feature importance

### Exercise 4: Semantic Challenge
**Image**: Autumn forest (complex!)
**Task**: Compare Tab 3 vs Tab 4
**Expected**: Students see ResNet18's advantage for complex scenes

### Exercise 5: Design Your Own
**Task**:
- Choose an image
- Predict which method works best
- Test hypothesis
- Explain why

---

## ğŸ’¡ Teaching Tips

### Make it Interactive
- Let students control the sliders
- Ask predictions before running
- Encourage experimentation

### Use Analogies
- **RGB clustering** = "Sorting crayons by color"
- **Position clustering** = "Organizing desk by location (top shelf, bottom shelf)"
- **ResNet18** = "Expert artist who understands what things ARE, not just colors"

### Common Misconceptions

**Misconception 1**: "More clusters = better"
- Show: K=10 creates tiny fragments
- Explain: Need to choose K based on image content

**Misconception 2**: "Deep learning always better"
- Show: RGB works perfectly for tulip field
- Explain: Simplicity has value!

**Misconception 3**: "Features are just numbers"
- Explain: Features = how we describe data
- Different features â†’ different results

---

## ğŸ“Š Assessment Ideas

### Quick Check (During Demo)
- "What are the features in RGB clustering?" [R, G, B]
- "Why does sky and ocean merge in RGB?" [Same color]
- "How does position help?" [Separates by location]

### Conceptual Questions
1. Explain why RGB+Position works better than RGB alone
2. What is a "feature vector"?
3. Why is ResNet18 slower but better for complex scenes?

### Hands-on Assessment
- Give students a new image (not in samples)
- Ask: Which method would work best? Why?
- Have them test and explain results

---

## ğŸ“ Learning Outcomes

### After this demo, students can:

âœ… **Define** what a feature is
âœ… **Explain** K-Means clustering
âœ… **Compare** hand-crafted vs learned features
âœ… **Apply** different clustering methods appropriately
âœ… **Analyze** trade-offs between methods
âœ… **Understand** basics of transfer learning

---

## ğŸ”— Connections to Other Topics

### Links to:
- **Supervised learning**: ResNet18 was trained supervised
- **Unsupervised learning**: K-Means is unsupervised
- **Feature engineering**: Tab 3 teaches feature design
- **Transfer learning**: Using pretrained ResNet18
- **Computer vision**: Segmentation task
- **Dimensionality**: 3D â†’ 5D â†’ 512D progression

---

## ğŸ“š Follow-up Resources

**After this demo, point students to**:
1. DINOv3 app (more advanced clustering)
2. Sklearn K-Means documentation
3. ResNet paper (He et al., 2015)
4. Transfer learning tutorials

---

## â±ï¸ Time Estimates

| Section | Time |
|---------|------|
| Introduction | 5 min |
| RGB Clustering | 10 min |
| Position Clustering | 10 min |
| Combined Approach | 15 min |
| Deep Learning | 20 min |
| Comparison | 10 min |
| **Total** | **70 min** |

Add 10-20 minutes for exercises and discussion.

---

## ğŸ‰ Key Takeaways

**Main messages**:
1. **Features matter** - How you describe data affects results
2. **No free lunch** - Each method has trade-offs
3. **Combine approaches** - RGB+Position often best balance
4. **Deep learning helps** - But not always necessary!
5. **Experiment!** - Try different methods, understand when each works

**The journey**: Simple (RGB) â†’ Spatial (XY) â†’ Combined (RGB+XY) â†’ Deep (ResNet18)

This mirrors the history of computer vision! ğŸš€
