# Grad-CAM Interactive Explorer

An interactive Streamlit app that visualizes Gradient-weighted Class Activation Mapping (Grad-CAM) step-by-step on MNIST digits.

**Self-contained educational experience** - Each step includes detailed explanations, intuitions, and code snippets to help learners understand exactly how Grad-CAM works!

## Features

- **Interactive Image Selection**: Choose by index or pick from a visual grid (50 images at a time)
- **Step-by-Step Visualization**: See each stage of the Grad-CAM algorithm with detailed explanations
- **16 Feature Maps**: Visualize all conv2 feature channels in a 4×4 grid with colorbars
- **Detailed Averaging Example**: See exactly how Channel 0's 8×8 gradients become a single weight
- **Channel Importance**: Bar chart showing which channels matter most, with top positive/negative contributors
- **High Resolution Figures**: 150 DPI for crisp, publication-quality visualizations
- **Collapsible Code**: Each step has expandable code snippets showing the PyTorch implementation
- **Educational Explanations**:
  - Why we use conv2 (last conv layer preserves spatial info)
  - What gradients mean (sensitivity to changes)
  - Why global average pooling (reduce 1024 numbers to 16)
  - How weighted sum works (combine important features)
  - How to interpret the final heatmap
- **No Emojis**: Clean, professional interface suitable for academic use

## Installation

1. Install dependencies:
```bash
pip install torch torchvision streamlit matplotlib numpy
```

2. Train the model (if not already done):
```bash
python train_model.py
```

This will download MNIST and train a LeNet model for 5 epochs (~2 minutes).

## Running the App

```bash
streamlit run app.py
```

The app will open in your browser at `http://localhost:8501`

## How to Use

1. **Select an Image**: Use the sidebar to choose an image index (0-9999)
2. **Choose Target Class**:
   - Check "Use predicted class" to explain the model's prediction
   - Or uncheck and select a different class to see counterfactual explanations
3. **Explore Each Step**:
   - Conv2 feature maps (16 channels, 8×8 each)
   - Gradients showing influence on target class
   - Global average pooling → channel importance weights
   - Weighted sum to create the heatmap
   - Final overlay visualization

## What is Grad-CAM?

Grad-CAM (Gradient-weighted Class Activation Mapping) is a visualization technique that shows which regions of an input image are important for a CNN's prediction.

**Key Idea**:
- Use gradients of the target class w.r.t. feature maps
- Weight each feature map by its importance
- Create a heatmap showing discriminative regions

**Paper**: Selvaraju et al. (2017) - [arXiv:1610.02391](https://arxiv.org/abs/1610.02391)

## Files

- `app.py` - Main Streamlit application
- `train_model.py` - Script to train LeNet on MNIST
- `lenet_mnist.pth` - Pre-trained model weights (generated by train_model.py)
- `README.md` - This file

## Architecture

The app uses a classic LeNet architecture:
- Conv1: 1→6 channels, 5×5 kernel
- MaxPool 2×2
- Conv2: 6→16 channels, 5×5 kernel (hooked for Grad-CAM)
- MaxPool 2×2
- FC layers: 256→120→84→10

We hook conv2 output (8×8) for better spatial resolution than pooled features (4×4).
